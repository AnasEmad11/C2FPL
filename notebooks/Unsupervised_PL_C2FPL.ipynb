{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# probability model\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"/home/anas.al-lahham/Baseline_AD/RFS_AD/iterative_UCF_labels/concat_UCF.npy\") #UCF\n",
    "# train_data = np.load(\"/home/anas.al-lahham/AD_Unsupervised/concat_XD_I3D.npy\") #XD\n",
    "train_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nalist = np.load(\"nalist.npy\") #UCF\n",
    "# nalist = np.load(\"nalist_XD.npy\") #XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_gauss(X):\n",
    "    m = X.shape[0]   # using only first dimension as we know it has only one feature - l2 norm\n",
    "    \n",
    "    mu = np.mean(X, axis=0)\n",
    "    var = np.cov(X.T)\n",
    "    \n",
    "    return mu, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_repr = []\n",
    "for i, (fromid, toid) in enumerate(nalist):\n",
    "    new_repr.append(train_data[fromid:toid])\n",
    "\n",
    "len(new_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_repr[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(data):\n",
    "\n",
    "    l2_norm = np.sum(np.square(data), axis=2)\n",
    "    n_train_crop_l2_norm_mean = np.mean(l2_norm, axis= 1)\n",
    "\n",
    "    return n_train_crop_l2_norm_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_gauss(X):\n",
    "    m = X.shape[0]   # using only first dimension as we know it has only one feature - l2 norm\n",
    "    \n",
    "    mu = np.mean(X, axis=0)\n",
    "    var = np.cov(X.T)\n",
    "    \n",
    "    return mu, var\n",
    "\n",
    "def covariance_mat(X):\n",
    "    X = np.mean(X , axis= 1)\n",
    "    X =  X.transpose(1,0)\n",
    "    cov  = np.cov(X)\n",
    "\n",
    "    return cov\n",
    "\n",
    "def get_matrix(data):\n",
    "\n",
    "    l2_norm = np.sum(np.square(data), axis=2)\n",
    "    n_train_crop_l2_norm_mean = np.mean(l2_norm, axis= 1)\n",
    "\n",
    "    return n_train_crop_l2_norm_mean\n",
    "\n",
    "\n",
    "def diff_l2(new_repr):\n",
    "\n",
    "    l2_norms = []\n",
    "    for i in range(len(new_repr)):\n",
    "        l2_norms.append(get_matrix(new_repr[i]))\n",
    "\n",
    "    mean_v_l2 = []\n",
    "    for i in range(len(l2_norms)):\n",
    "        mean_v_l2.append(np.diff(l2_norms[i], n=1).max())\n",
    "    return mean_v_l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for i in range(len(new_repr)):\n",
    "\n",
    "    param = get_matrix(new_repr[i])\n",
    "    mu, var = estimate_gauss(param)\n",
    "\n",
    "    params.append((mu, var, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(params).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import time\n",
    "\n",
    "\n",
    "gmm = GaussianMixture(n_components=2, max_iter=150, random_state=0, covariance_type='spherical')\n",
    "# gmm_scores = gmm.score_samples(params)\n",
    "labels = gmm.fit_predict(params)\n",
    "\n",
    "y_gmm = gmm.fit_predict(params)\n",
    "print(y_gmm.sum(), y_gmm.sum() / len(y_gmm))\n",
    "\n",
    "\n",
    "score = y_gmm \n",
    "score = gmm.score_samples(params) \n",
    "pct_threshold = np.percentile(score, 3)\n",
    "print(f'The threshold of the score is {pct_threshold:.2f}') \n",
    "res = np.array([1 if x < pct_threshold else 0 for x in score]) \n",
    "print(res.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_portion = np.where(labels == 1)[0]\n",
    "normal_portion = np.where(labels == 0)[0]\n",
    "normal_portion.shape, abnormal_portion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params = np.array(params)[normal_portion]\n",
    "a_params = np.array(params)[abnormal_portion]\n",
    "n_params.shape, a_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abag = list(zip(list(np.array(params)[abnormal_portion]), abnormal_portion))\n",
    "nbag = list(zip(list(np.array(params)[normal_portion]), normal_portion))\n",
    "len(abag), len(nbag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nu = 1.0\n",
    "step = 1\n",
    "import time\n",
    "start = time.time()\n",
    "while len(abag) / len(nbag) < nu:\n",
    "    \n",
    "    temp_bag = nbag\n",
    "    y_gmm = gmm.fit_predict([list(x[0]) for x in np.array(temp_bag)])\n",
    "    score = y_gmm \n",
    "    score = gmm.score_samples([list(x[0]) for x in np.array(temp_bag)]) \n",
    "    pct_threshold = np.percentile(score, 3) \n",
    "    res = np.array([1 if x < pct_threshold else 0 for x in score]) \n",
    "    print(f'The threshold of the score in step {step} is {pct_threshold:.2f}, abnormal part: {res.sum()}') \n",
    "    \n",
    "    abnormal_portion = np.where(res == 1)[0]\n",
    "    normal_portion = np.where(res == 0)[0]\n",
    "    \n",
    "    abag += [(x[0], x[1]) for x in np.array(temp_bag)[abnormal_portion]]\n",
    "    nbag = [(x[0], x[1]) for x in np.array(temp_bag)[normal_portion]]\n",
    "\n",
    "    step += 1\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(np.array([x[1] for x in abag]) < 810)[0].shape, len([x[1] for x in abag]))\n",
    "print('correctness acc: ', np.where(np.array([x[1] for x in abag]) < 810)[0].shape[0] / len([x[1] for x in abag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(np.array([x[1] for x in nbag]) > 810)[0].shape, len([x[1] for x in nbag]))\n",
    "print('correctness acc: ', np.where(np.array([x[1] for x in nbag]) > 810)[0].shape[0] / len([x[1] for x in nbag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [k[1] for k in sorted([(x[1], 1.0) for x in abag] + [(x[1], 0.0) for x in nbag], key=lambda z: z[0])]\n",
    "sum(temp), len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal set creation\n",
    "normal_set = {}\n",
    "\n",
    "for i in range(len(new_repr)):\n",
    "    if temp[i] == 0.0:\n",
    "        normal_set[i] = new_repr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abnormal set creation\n",
    "abnormal_set = {}\n",
    "for i in range(len(new_repr)):\n",
    "    if temp[i] == 1.0:\n",
    "        abnormal_set[i] = new_repr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_norms_N = np.empty(0,)\n",
    "for (idel, sample) in normal_set.items():\n",
    "    \n",
    "    # print(sample.shape)\n",
    "    \n",
    "\n",
    "    l2_norms_N = np.append(l2_norms_N,get_matrix(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normal_set), len(abnormal_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_GMM, var_GMM = estimate_gauss(np.array(l2_norms_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability model\n",
    "from scipy.stats import multivariate_normal\n",
    "p = multivariate_normal(mu_GMM, var_GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = {} \n",
    "length = 0.2 \n",
    "for (idel, sample) in abnormal_set.items(): \n",
    "\n",
    "    # feature extraction \n",
    "    # sample_matrix = np.sum(np.square(sample), axis=1)  # for just l2\n",
    "    sample_matrix = get_matrix(sample)\n",
    "    \n",
    "    # get p values\n",
    "    probs = p.pdf(sample_matrix)\n",
    "    temp_list = []\n",
    "    temp_list += [0.0] * len(probs)\n",
    "    \n",
    "    window_size = int(len(probs) * length)  # fixed\n",
    "    temp = []\n",
    "    for idx in range(0, len(probs) - window_size + 1):\n",
    "        arr = 0\n",
    "        for i in range(idx, idx + window_size - 1):\n",
    "            arr += abs(probs[i+1] - probs[i])\n",
    "        temp.append(arr)\n",
    "\n",
    "    for i in range(temp.index(max(temp)), temp.index(max(temp)) + window_size):\n",
    "        temp_list[i] = 1.0\n",
    "\n",
    "    ground_truth[idel] = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gt = []\n",
    "abnormal_gt = []\n",
    "for i in range(len(new_repr)):\n",
    "    if i in normal_set.keys():\n",
    "        final_gt += [0.0] * new_repr[i].shape[0]\n",
    "    else:\n",
    "        final_gt += ground_truth[i]\n",
    "        abnormal_gt+= ground_truth[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('unsupervised_PL/'+'UCF_labels_entropy_1.npy', final_gt) #UCF\n",
    "# np.save('Unsup_labels/'+'XD_I3D_unsup_labels_10_V2_GMM.npy', final_gt) #XD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
